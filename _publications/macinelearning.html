---
title: "🧠 AI & Machine Learning"
layout: page
permalink: /ai-ml/
---

<h2>🚀 Overview</h2>
<p>
Welcome to my AI/ML portfolio. This section showcases my work in machine learning, generative AI, large language models, and MLOps. My focus lies in building scalable systems that combine state-of-the-art modeling with production-grade deployment. Projects here span across <strong>Reinforcement Learning</strong>, <strong>Diffusion-based Generation</strong>, <strong>Multimodal Transformers</strong>, and <strong>LLM Tooling</strong>, developed through both research and industry settings.
</p>

<hr/>

<h2>🔁 Optimizing RAG with Multi-Agent Reinforcement Learning</h2>
<p><a href="https://github.com/raviraj988">🔗 GitHub Repo</a></p>
<img src="../images/projects/rag-ppo.png" alt="RAG + PPO" style="float: right; max-width: 300px; margin-left: 20px;">
<ul style="font-size:16px;">
  <li>Designed a <strong>Multi-Agent Reinforcement Learning</strong> framework for RAG, modeling query design, document retrieval, and answer generation as cooperative agents jointly optimized via <strong>PPO</strong> under a unified <strong>F1-based reward</strong> signal.</li>
  <li>Implemented <strong>FAISS</strong> search with <strong>sentence-transformers/all-MiniLM-L6-v2</strong> embeddings to enable efficient top-K passage retrieval over a custom <strong>SQuAD</strong> corpus, all within a reproducible <strong>Conda</strong> environment.</li>
  <li>Implemented Warm-start for each agent by employing <strong>PEFT’s LoRA</strong> by freezing <strong>96.65%</strong> of weights, to fine-tuning LoRA adapters on <strong>5,000 SQuAD QA pairs</strong> before any RL, which improved sample efficiency and stabilized the subsequent PPO loop.</li>
  <li>Implemented a <strong>PPO loop</strong> using <strong>TRL’s PPOTrainer</strong> that fine-tunes only the LoRA adapters and value head by iterating query rewrite, retrieve, generate with a unified reward signal, significantly improving QA performance over SFT.</li>
  <li>Designed a multi-agent <strong>PPO-based framework</strong> where query rewriting, document retrieval, and generation are jointly optimized using shared rewards.</li>
  <li>Used <strong>LoRA adapters</strong> for warm-start fine-tuning on SQuAD and built a reproducible pipeline with <strong>TRL’s PPOTrainer</strong>, improving factual consistency and generation relevance.</li>
</ul>

<hr/>

<h2>🖼️ Multimodal Transformer for Image-Conditioned Generation</h2>
<p><a href="https://github.com/yourusername/siglip-gemma">🔗 GitHub Repo</a></p>
<img src="../images/projects/siglip-gemma.png" alt="Multimodal Transformer" style="float: right; max-width: 300px; margin-left: 20px;">
<ul style="font-size:16px;">
  <li>Designed and implemented a <strong>multimodal transformer</strong> integrating a SigLIP-style Vision Transformer with a Gemma-based causal decoder for image-grounded generation tasks such as captioning and visual question answering.</li>
  <li>Engineered <strong>autoregressive decoding</strong> with KV caching and <strong>Rotary Positional Embeddings</strong>, reducing inference latency by <strong>40%</strong> per token on long sequences.</li>
  <li>Built a <strong>PaLI-inspired tokenizer</strong> pipeline with image-token prefixing and robust image normalization, improving input alignment and reducing token mismatch errors by <strong>23%</strong>.</li>
  <li>Enabled diverse generation using <strong>temperature-scaled top-p sampling</strong>; achieved a <strong>+3.7 BLEU-4</strong> score improvement over greedy decoding on benchmark prompts.</li>
</ul>

<hr/>

<h2>🎨 Latent Diffusion Model for Text-to-Image Synthesis</h2>
<p><a href="https://github.com/hkproj/pytorch-stable-diffusion">🔗 GitHub Repo</a></p>
<img src="../images/projects/latent-diffusion.png" alt="Stable Diffusion" style="float: right; max-width: 300px; margin-left: 20px;">
<ul style="font-size:16px;">
  <li>Developed a complete <strong>multimodal pipeline</strong> integrating <strong>CLIP</strong>-based language encoder, <strong>VAE</strong>, and <strong>U-Net</strong>-based diffusion model for high-fidelity text-to-image generation.</li>
  <li>Achieved <strong>4× faster inference</strong> over pixel-space models by operating in latent space (64×64 vs. 512×512), reducing memory and compute by over <strong>85%</strong>.</li>
  <li>Implemented <strong>Classifier-Free Guidance</strong> to enhance prompt alignment, improving semantic accuracy by <strong>8%</strong> (measured via CLIPScore).</li>
  <li>Enabled multimodal capabilities: <strong>text-to-image, image-to-image translation, and inpainting</strong>, through a unified conditional diffusion framework.</li>
  <li>Reproduced <strong>Stable Diffusion</strong> from scratch with PyTorch, integrating CLIP, VAE, and U-Net.</li>
  <li>Achieved <strong>FID: 12.4</strong> and <strong>CLIPScore: 0.32</strong> on COCO; optimized <strong>12-layer Transformer</strong> with 4000+ tokens/sec throughput on A100.</li>
</ul>

<hr/>

<h2>📊 Semi-Supervised Learning with Deep Generative Models</h2>
<p><a href="https://github.com/raviraj988/Enhancing_SSL_Using_Deep_Gen_Models">🔗 GitHub Repo</a></p>
<img src="../images/projects/ssl-dgm.png" alt="Semi-supervised Learning" style="float: right; max-width: 300px; margin-left: 20px;">
<ul style="font-size:16px;">
  <li>Conducted an in-depth survey of <strong>semi-supervised learning</strong> with <strong>deep generative models</strong> and implemented Kingma et al.’s M2 approach on <strong>MNIST and CIFAR-10</strong>.</li>
  <li>Matched paper results: <strong>94.8% test accuracy</strong> on MNIST (1k labels) and <strong>63.1%</strong> on CIFAR-10 (4k labels), establishing a reliable baseline.</li>
  <li>Performed mathematical and experimental analysis of <strong>ELBO</strong> and introduced improvements: entropy penalization, mutual information maximization, and smoothed-label integration.</li>
  <li>Delivered a <strong>4% accuracy improvement</strong> on MNIST and a <strong>2.5% gain</strong> on CIFAR-10, along with a <strong>15% reduction</strong> in classifier entropy.</li>
</ul>

<hr/>

<h2>🛰️ 3D Point Cloud Segmentation via 2D Voting</h2>
<p><a href="https://github.com/raviraj988/3D-POINT-CLOUD-SEGMENTATION-USING-2D-IMAGE-SEGMENTATION">🔗 GitHub Repo</a></p>
<img src="../images/projects/pointcloud.png" alt="Point Cloud" style="float: right; max-width: 300px; margin-left: 20px;">
<ul style="font-size:16px;">
  <li>Developed a novel <strong>3D point cloud segmentation</strong> framework leveraging <strong>2D image segmentation models</strong> (OneFormer) and a voting-based projection mechanism.</li>
  <li>Used <strong>RGB images, depth maps, and LiDAR data</strong> captured with iPhone 13 Pro, transferring semantic labels via voting to 3D point clouds.</li>
  <li>Achieved <strong>96.5%</strong> segmentation accuracy, matching <strong>PointFormer</strong>, with significantly lower computation and memory cost.</li>
</ul>

<hr/>

<h2>🩺 Multi-Agent Medical Appointment System</h2>
<p><a href="https://github.com/raviraj988/Multi_Agent_System_For_Doctor-s_Appointment">🔗 GitHub Repo</a></p>
<img src="../images/projects/doctor-agent.png" alt="Medical Appointment AI" style="float: right; max-width: 300px; margin-left: 20px;">
<ul style="font-size:16px;">
  <li>Built a modular <strong>multi-agent AI system</strong> using <strong>LangChain</strong> and <strong>LangGraph</strong>, with a <strong>supervisor-agent architecture</strong> to route user queries.</li>
  <li>Engineered a <strong>full-stack solution</strong> using <strong>FastAPI</strong> and <strong>Streamlit</strong> for real-time appointment management via natural language.</li>
  <li>Improved query-to-response time by <strong>~60%</strong> by automating slot filtering and delegation across <strong>4,000+ records</strong>, reducing manual effort from ~30s to <strong>under 12s</strong>.</li>
</ul>

<hr/>

<h2>💬 RAG-Powered Customer Support Agent</h2>
<p><a href="https://github.com/raviraj988/RAG_Customer_support_System">🔗 GitHub Repo</a></p>
<img src="../images/projects/rag-chatbot.png" alt="RAG Chatbot" style="float: right; max-width: 300px; margin-left: 20px;">
<ul style="font-size:16px;">
  <li>Built an end-to-end <strong>ETL pipeline</strong> using <strong>Pandas</strong> to parse Flipkart reviews into LangChain documents and ingest into <strong>AstraDB Vector Store</strong>.</li>
  <li>Integrated <strong>Google Gemini-1.5-Pro embeddings</strong> and <strong>LangChain’s ChatPromptTemplate</strong> for context-aware retrieval and response generation.</li>
  <li>Developed a RESTful <strong>FastAPI backend</strong> with environment-driven configuration (<strong>PyYAML</strong>, <strong>python-dotenv</strong>) and AJAX UI using <strong>Jinja2, Bootstrap 4</strong>, and <strong>jQuery</strong>.</li>
</ul>

<hr/>

<p>🧠 More projects coming soon ...</p>
